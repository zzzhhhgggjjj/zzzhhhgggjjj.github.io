<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>在线教育离线数仓之数据采集</title>
      <link href="/wenzhang/%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
      <url>/wenzhang/%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<!-- <div class="video-container">[up主专用，视频内嵌代码贴在这]</div> --><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: 在线教育离线数仓之数据采集<p>date: 1737542912000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/wenzhang/hello-world/"/>
      <url>/wenzhang/hello-world/</url>
      
        <content type="html"><![CDATA[<h1 id="博客预览"><a href="#博客预览" class="headerlink" title="博客预览"></a>博客预览</h1><blockquote><p>hexo cl; hexo s</p></blockquote><h1 id="推送"><a href="#推送" class="headerlink" title="推送"></a>推送</h1><blockquote><p>hexo cl; hexo g; hexo d</p></blockquote><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><h2 id="基本语法-1"><a href="#基本语法-1" class="headerlink" title="基本语法"></a>基本语法</h2><h3 id="基本语法-2"><a href="#基本语法-2" class="headerlink" title="基本语法"></a>基本语法</h3><p><strong>引用</strong></p><ol><li>hjjk </li><li>jkdsfjl</li></ol><ul><li>skolfakashjd </li><li>kdsfjfjljds<br>djlksgjdfjksldfjl</li></ul><ul><li>sakllflj</li></ul><ul><li>sakhaklfhk</li></ul><ol><li>lsalk</li></ol><table><thead><tr><th>表头 1</th><th>表头 2</th></tr></thead><tbody><tr><td>内容 1</td><td>内容 2</td></tr><tr><td>内容 3</td><td>内容 4</td></tr></tbody></table><div style="text-align: center;"><table><thead><tr><th align="right">kalfl</th><th align="center">ldskkfldg</th></tr></thead><tbody><tr><td align="right">lslfjkk</td><td align="center">kdjfglk</td></tr></tbody></table></div><div style="text-align: center;"><table><thead><tr><th>服务名称</th><th>子服务</th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td>HDFS</td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td>HDFS</td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Yarn</td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume(采集日志)</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka日志）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Flume（消费Kafka业务）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td>Hive</td><td>√</td><td></td><td></td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>DataX</td><td>DataX</td><td>√</td><td></td><td></td></tr><tr><td>Maxwell</td><td>Maxwell</td><td>√</td><td></td><td></td></tr><tr><td>Spark</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>ClickHouse</td><td></td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>ApiApplicationServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>AlertServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>MasterServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>WorkerServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>LoggerServer</td><td>√</td><td>√</td><td>√</td></tr></tbody></table></div>`dfhjkgh`<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lhjsdfkhs</span><br><span class="line">jkhdsfkj</span><br></pre></td></tr></table></figure><p><a href="https://cmliussss.com/p/HexoBlogNo2/">超链接</a>：<a href="https://cmliussss.com/p/HexoBlogNo2/">https://cmliussss.com/p/HexoBlogNo2/</a></p><p>请<a href="https://cmliussss.com/p/HexoBlogNo2/">点我</a></p><h1 id="服务部署情况"><a href="#服务部署情况" class="headerlink" title="服务部署情况"></a>服务部署情况</h1><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>在线教育离线数仓使用的脚本合集</title>
      <link href="/wenzhang/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE/"/>
      <url>/wenzhang/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="1-集群执行命令脚本："><a href="#1-集群执行命令脚本：" class="headerlink" title="1. 集群执行命令脚本："></a>1. 集群执行命令脚本：</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"> </span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo --------- $i ----------</span><br><span class="line">    ssh $i &quot;$*&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="2-集群同步脚本"><a href="#2-集群同步脚本" class="headerlink" title="2. 集群同步脚本"></a>2. 集群同步脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录(dirname获取绝对路径父目录,相对路径获取的是.）</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir #-av是打印进度的</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="3-Hadoop启动脚本"><a href="#3-Hadoop启动脚本" class="headerlink" title="3. Hadoop启动脚本"></a>3. Hadoop启动脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;No Args Input...&quot;</span><br><span class="line">    exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">        echo &quot; =================== 启动 hadoop集群 ===================&quot;</span><br><span class="line"></span><br><span class="line">        echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/sbin/start-dfs.sh&quot;</span><br><span class="line">        echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line">        ssh hadoop103 &quot;/opt/module/hadoop/sbin/start-yarn.sh&quot;</span><br><span class="line">        echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/bin/mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">        echo &quot; =================== 关闭 hadoop集群 ===================&quot;</span><br><span class="line"></span><br><span class="line">        echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/bin/mapred --daemon stop historyserver&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line">        ssh hadoop103 &quot;/opt/module/hadoop/sbin/stop-yarn.sh&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="4-Zookeeper启动脚本"><a href="#4-Zookeeper启动脚本" class="headerlink" title="4. Zookeeper启动脚本"></a>4. Zookeeper启动脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">判断是否输入参数</span></span><br><span class="line">if [ $# -lt 1 ]; then</span><br><span class="line">  echo &quot;请输入参数&quot;</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo ---------- zookeeper $i 启动 ------------</span><br><span class="line">                ssh $i &quot;/opt/module/zookeeper/bin/zkServer.sh start&quot;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo ---------- zookeeper $i 停止 ------------    </span><br><span class="line">                ssh $i &quot;/opt/module/zookeeper/bin/zkServer.sh stop&quot;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;status&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo ---------- zookeeper $i 状态 ------------    </span><br><span class="line">                ssh $i &quot;/opt/module/zookeeper/bin/zkServer.sh status&quot;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="5-Kafka启动脚本"><a href="#5-Kafka启动脚本" class="headerlink" title="5. Kafka启动脚本"></a>5. Kafka启动脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">判断是否输入参数</span></span><br><span class="line">if [ $# -lt 1 ]; then</span><br><span class="line">  echo &quot;请输入参数&quot;</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo &quot; --------启动 $i Kafka-------&quot;</span><br><span class="line">        ssh $i &quot;/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties&quot;</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo &quot; --------停止 $i Kafka-------&quot;</span><br><span class="line">        ssh $i &quot;/opt/module/kafka/bin/kafka-server-stop.sh &quot;</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><!-- <div class="video-container">[up主专用，视频内嵌代码贴在这]</div> --><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>大数据项目之在线教育离线数仓</title>
      <link href="/wenzhang/%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E6%96%B0%E7%9A%84%E5%8D%9A%E6%96%87/"/>
      <url>/wenzhang/%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E6%96%B0%E7%9A%84%E5%8D%9A%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="大数据开发项目之在线教育离线数仓从零到一（学习项目）"><a href="#大数据开发项目之在线教育离线数仓从零到一（学习项目）" class="headerlink" title="大数据开发项目之在线教育离线数仓从零到一（学习项目）"></a>大数据开发项目之在线教育离线数仓从零到一（学习项目）</h1><p>本文详细介绍了大数据开发项目之在线教育离线数仓的开发过程，从零到一，包括项目背景、需求分析、设计思路、技术选型、开发环境搭建、数据采集、数仓搭建、</p><h2 id="项目整体流程"><a href="#项目整体流程" class="headerlink" title="项目整体流程"></a>项目整体流程</h2><p>该项目是一个在线教育大数据开发项目，旨在构建离线数仓，对在线教育业务数据进行分析处理，以支持企业决策。以下是项目的详细流程：</p><h3 id="1-业务流程与数据来源"><a href="#1-业务流程与数据来源" class="headerlink" title="1. 业务流程与数据来源"></a>1. 业务流程与数据来源</h3><ul><li><strong>业务流程</strong>：用户从在线教育网站首页开始浏览课程，可通过分类查询或全文检索寻找课程，找到后可添加到购物车、登录、结算，生成订单和支付数据，订单生成后会进行跟踪处理。</li><li><strong>数据来源</strong>：包括用户行为数据（通过前端埋点采集，存储在 HDFS 文件中）和业务数据（存储在 MySQL 中）。(因为本项目为学习项目，所以数据来源均为数据模拟器模拟的虚拟数据)</li></ul><h3 id="2-系统数据流程设计"><a href="#2-系统数据流程设计" class="headerlink" title="2. 系统数据流程设计"></a>2. 系统数据流程设计</h3><ul><li><strong>集群流程图</strong>：业务服务器与 App 业务交互，通过 Nginx 进行数据传输。日志数据经日志服务器采集，可采用 flume 采集方式，部分数据经消息缓存后存入 Kafka。业务数据通过 DataX 每日同步从 MySQL 数据库导入。数据在集群中经过 ODS、DWD、DWS 等层的处理，最终用于可视化。<br><img src="https://img01.zzh36111.us.kg/20250122151413.png" alt="流程图"><br>问：为什么不直接使用flume把数据采集到hdfs，要在之间加一个kafka呢？可以把Kafka换为flume聚合吗？</li><li><strong>集群特点</strong>：具备多数据源对接能力，可进行离线批量和在线实时处理，有统一的集群管理配置监控平台，并实现用户认证和权限管理，满足多租户需求。</li></ul><h3 id="3-技术选型"><a href="#3-技术选型" class="headerlink" title="3. 技术选型"></a>3. 技术选型</h3><ul><li><p><strong>Apache 框架版本</strong>：确定了 Hadoop、Flume、Kafka、Hive、Sqoop 等多种技术框架的具体版本，每个版本都有其特定的功能特点，以满足项目需求。</p><table><thead><tr><th>框架</th><th>版本</th></tr></thead><tbody><tr><td>Hadoop</td><td>3.1.3</td></tr><tr><td>Zookeeper</td><td>3.5.7</td></tr><tr><td>MySQL</td><td>5.7.16</td></tr><tr><td>Hive</td><td>3.1.2</td></tr><tr><td>Flume</td><td>1.9.0</td></tr><tr><td>Kafka</td><td>3.0.0</td></tr><tr><td>Spark</td><td>3.0.0</td></tr><tr><td>DataX</td><td>3.0.0</td></tr><tr><td>Superset</td><td>1.3.2</td></tr><tr><td>DolphinScheduler</td><td>2.0.3</td></tr><tr><td>Maxwell</td><td>1.29.2</td></tr></tbody></table></li><li><p><strong>服务器选型</strong>：因为本项目仅为学习项目所以服务器选型比较简单仅为三台虚拟机。</p></li></ul><h3 id="4-集群规模规划"><a href="#4-集群规模规划" class="headerlink" title="4. 集群规模规划"></a>4. 集群规模规划</h3><ul><li><p><strong>集群规划</strong>：详细规划了各服务器节点上部署的组件，如 DataNode、NodeManager、ResourceManager 等在不同服务器上的分布。</p><table><thead><tr><th>服务名称</th><th>子服务</th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td>HDFS</td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td>HDFS</td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Yarn</td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume(采集日志)</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka日志）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Flume（消费Kafka业务）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td>Hive</td><td>√</td><td></td><td></td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>DataX</td><td>DataX</td><td>√</td><td></td><td></td></tr><tr><td>Maxwell</td><td>Maxwell</td><td>√</td><td></td><td></td></tr><tr><td>Spark</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>ApiApplicationServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>AlertServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>MasterServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>WorkerServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>LoggerServer</td><td>√</td><td>√</td><td>√</td></tr></tbody></table></li></ul><!-- ### 5. 数据生成与分析指标 - **数据生成器使用**：通过上传相关配置文件（application.yml、path.json、logback.xml 等）到指定目录，并修改配置文件参数，可在虚拟机指定路径下生成日志数据并向业务数据库插入业务数据。可生成不同日期数据，且能灵活配置用户点击路径和日志生成路径。 - **分析指标**：涵盖流量主题（如各来源流量统计、路径分析、各来源下单统计）、用户主题（如用户变动统计、留存率、新增活跃统计等）、课程主题（如各分类课程交易统计、评价统计、试听留存统计等）、交易主题、考试主题、播放主题、完课主题等多方面的指标，每个指标都有明确的统计周期和粒度要求。 -->]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
