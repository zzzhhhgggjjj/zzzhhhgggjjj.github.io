<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>linux中出错处理方法</title>
      <link href="/wenzhang/Maxwell%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/"/>
      <url>/wenzhang/Maxwell%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="0-前言：这是错误的通用处理方法，我以maxwell启动失败为例，请根据具体情况进行调整。"><a href="#0-前言：这是错误的通用处理方法，我以maxwell启动失败为例，请根据具体情况进行调整。" class="headerlink" title="0. 前言：这是错误的通用处理方法，我以maxwell启动失败为例，请根据具体情况进行调整。"></a>0. 前言：这是错误的通用处理方法，我以maxwell启动失败为例，请根据具体情况进行调整。</h2><h2 id="1-查看日志文件"><a href="#1-查看日志文件" class="headerlink" title="1. 查看日志文件"></a>1. 查看日志文件</h2><p>找到maxwell的日志文件，一般在<code>~/maxwell/logs</code>目录下，根据具体情况进行调整。<br><img src="https://img01.zzh36111.us.kg/20250129160756.png" alt="这是我的日志文件目录"></p><h2 id="2-排查错误原因"><a href="#2-排查错误原因" class="headerlink" title="2. 排查错误原因"></a>2. 排查错误原因</h2><p>根据日志文件，找到error关键字，一般会有具体的错误原因。<br><img src="https://img01.zzh36111.us.kg/20250129161206.png" alt="这是我的日志文件中的error关键字"></p><h2 id="3-处理错误"><a href="#3-处理错误" class="headerlink" title="3. 处理错误"></a>3. 处理错误</h2><p>复制错误原因到搜索引擎或GPT，根据搜索结果进行错误处理。<br><img src="https://img01.zzh36111.us.kg/20250129162411.png" alt="根据GPT搜索结果排查下来发现是mysqlbinglog的配置问题"></p><div class="video-container">[up主专用，视频内嵌代码贴在这]</div><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: linux中出错处理方法<p>date: 1738137508000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>梳理</title>
      <link href="/wenzhang/%E6%A2%B3%E7%90%86/"/>
      <url>/wenzhang/%E6%A2%B3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>1.<br>&#x2F;opt&#x2F;module&#x2F;data_mocker目录下改<br>application.yml文件中的日期，注意首日要改</p><h1 id="清空"><a href="#清空" class="headerlink" title="清空"></a>清空</h1><p>mock.clear.busi: 1</p><h1 id="清空用户"><a href="#清空用户" class="headerlink" title="清空用户"></a>清空用户</h1><p>mock.clear.user: 1</p><p>2. </p><div class="video-container">[up主专用，视频内嵌代码贴在这]</div><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: 梳理<p>date: 1738130258000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>建模</title>
      <link href="/wenzhang/%E5%BB%BA%E6%A8%A1/"/>
      <url>/wenzhang/%E5%BB%BA%E6%A8%A1/</url>
      
        <content type="html"><![CDATA[<ol><li>熟悉业务<br>MySQL保存的不是行为数据，而是实体数据，状态数据。</li></ol><p>数据源-》数据加工-》数据统计-》数据分析-》数据展示-》数据决策</p><p>为什么分多成，因为一个指标可能要重复运算</p><p>数据采集当天计算所以要求数据采集占用时间短，所以ods与采集到的数据格式尽可能不变</p><ol><li>存储方式</li><li>数据格式</li><li>压缩方式<br>有些可以变</li><li>融合异构</li><li>汇总不同时间数</li></ol><p>数仓目的是分析<br>分层设计为了使数据体系更加清晰，便于管理。</p><p>因为有很多数据重复所以有维度dim</p><ol><li>er：使用面向对象的方式设计表在</li><li>1对多的关系，多的表中建外键比在多的表中建外键查询更高效。</li><li>1对1：主外键相同</li><li>多对多采用两张表很难实现，第三张表中建立两个外键，分别指向主表和从表。</li></ol><p>3nf<br>函数依赖</p><p>1nf：每个属性都只包含一个值。不可分解。<br>2nf：在1nf基础上，非主属性不能直接依赖于主键。<br>3nf：在2nf基础上，任何非主属性不能传递依赖于主键。 </p><p>er模型表太多，不适合统计分析，所以需要维度建模进行分层设计。</p><ol start="5"><li>维度：</li><li>数据统计：汇总数据（行为的结果）——–事实表</li><li>数据分析：角度（状态）———维度表</li></ol><p>分层设计是逻辑分层，按表名分层。</p><p>ods主要存储所以用gzip压缩效率较高，且不用格式转换，且不用格式转换就可以建表<br>指定表位置方便管理<br>为什么用外部表？<br>看是否有别人一起用<br>分区表：按时间分区，方便查询，提高查询效率。（不用分区，会生成多文件，大文件，查询时会扫描所有文件，效率低）<br>分区字段不会存到文件会放到路径中，所以使用采用分区表<br>设置严格的权限控制，防止误操作<br>日志表字段怎么选？<br>如果json属性和表字段相同，可以正常解析<br>如果json属性少表字段存在的可以正常解析不存在的解析为null<br>如果json属性多表字段不存在的不解析<br>如果json属性和表字段不区分大小写，可以正常解析</p><p>所以json表字段选最外层json对象属性为表字段，它是json的结构，所以用特殊类型</p><p>map 与 struct 区别<br>map：value类型统一，key个数可以变<br>struct：value类型可以不统一，key个数固定</p><p>时间戳，10位为秒，13位为毫秒用bigint存储</p><p>因为 datebase,table 属性与业务无关所以建表时不要</p><p>dim表：<br>应该为列存储适合统计，hive：orc<br>所以压缩应该snappy<br>全量<br>状态数据为了避免出现问题最好每天存一份全部数据（绝大多数都是全量表）<br>拉链<br>维度表<br>把有关联维度放到一张维度表，避免关联查询<br>如果维度表特别简单，可以不建维度表，直接在事实表中关联<br>只要可以用来分析的维度都是字段<br>确定字段来源（参考业务数据库的字段）<br>主维度：业务数据库主要分析字段的表<br>相关维度：业务数据库中存在关联关系的表<br>确定维度表字段：<br>字段越多越好（列存储不会影响查询效率）<br>编码和文字共存，<br>沉淀出通用属性</p><div class="video-container">[up主专用，视频内嵌代码贴在这]</div><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: 建模<p>date: 1737874753000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Datax</title>
      <link href="/wenzhang/Datax/"/>
      <url>/wenzhang/Datax/</url>
      
        <content type="html"><![CDATA[<h2 id="1-DataX概述"><a href="#1-DataX概述" class="headerlink" title="1.DataX概述"></a>1.DataX概述</h2><p>DataX是阿里巴巴开源的一个异构数据源离线同步工具，致力于实现包括关系型数据库（Mysql、Oracle等）、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p><h2 id="2-DataX作用"><a href="#2-DataX作用" class="headerlink" title="2.DataX作用"></a>2.DataX作用</h2><p><img src="https://img01.zzh36111.us.kg/20250124141748.png" alt="DataX作为中间传输载体负责连接数据各种数据源"></p><h2 id="3-DataX支持的数据源"><a href="#3-DataX支持的数据源" class="headerlink" title="3.DataX支持的数据源"></a>3.DataX支持的数据源</h2><p>DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NoSQL、大数据计算系统都已经接入，支持如下：</p><table><thead><tr><th>类型</th><th>数据源</th><th>Reader（读）</th><th>Writer（写）</th></tr></thead><tbody><tr><td>RDBMS 关系型数据库</td><td>MySQL</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Oracle</td><td>✔</td><td>✔</td></tr><tr><td></td><td>OceanBase</td><td>✔</td><td>✔</td></tr><tr><td></td><td>SQLServer</td><td>✔</td><td>✔</td></tr><tr><td></td><td>PostgreSQL</td><td>✔</td><td>✔</td></tr><tr><td></td><td>DRDS</td><td>✔</td><td>✔</td></tr><tr><td></td><td>通用 RDBMS</td><td>✔</td><td>✔</td></tr><tr><td>阿里云数仓数据库</td><td>ODPS</td><td>✔</td><td>✔</td></tr><tr><td></td><td>ADS</td><td>✔</td><td>✔</td></tr><tr><td></td><td>OSS</td><td>✔</td><td>✔</td></tr><tr><td></td><td>OCS</td><td>✔</td><td>✔</td></tr><tr><td>NoSQL 数据存储</td><td>OTS</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Hbase0.94</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Hbase1.1</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Phoenix4.x</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Phoenix5.x</td><td>✔</td><td>✔</td></tr><tr><td></td><td>MongoDB</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Hive</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Cassandra</td><td>✔</td><td>✔</td></tr><tr><td>无结构化数据存储</td><td>TxtFile</td><td>✔</td><td>✔</td></tr><tr><td></td><td>FTP</td><td>✔</td><td>✔</td></tr><tr><td></td><td>HDFS</td><td>✔</td><td>✔</td></tr><tr><td></td><td>Elasticsearch</td><td>✔</td><td>✔</td></tr><tr><td>时间序列数据库</td><td>OpenTSDB</td><td>✔</td><td></td></tr><tr><td></td><td>TSDB</td><td>✔</td><td>✔</td></tr></tbody></table><h2 id="3-DataX使用"><a href="#3-DataX使用" class="headerlink" title="3.DataX使用"></a>3.DataX使用</h2><p>DataX的使用非常简单，用户仅需要根据自己同步数据的数据源和目的地的类型来选择相应的Reader和Writer插件即可，并将Reader和Writer插件的信息配置在一个json文件中，然后，在执行命令时，指定配置文件提交数据同步任务即可。</p><h3 id="3-1DataX配置文件格式"><a href="#3-1DataX配置文件格式" class="headerlink" title="3.1DataX配置文件格式"></a>3.1DataX配置文件格式</h3><p>这里以同步HDFS数据到MySQL为例，说明DataX的配置文件格式。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfsreader&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/base_province&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;defaultFS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://hadoop102:8020&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;*&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fileType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;compress&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gzip&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;encoding&quot;</span><span class="punctuation">:</span> <span class="string">&quot;UTF-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;nullFormat&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\\N&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fieldDelimiter&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\t&quot;</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;writer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mysqlwriter&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;writeMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;replace&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;username&quot;</span><span class="punctuation">:</span> <span class="string">&quot;root&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123456&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="string">&quot;id&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;name&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;region_id&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;area_code&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;iso_code&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;iso_3166_2&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;connection&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;jdbcUrl&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jdbc:mysql://hadoop102:3306/gmall?useUnicode=true&amp;characterEncoding=utf-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                  <span class="string">&quot;test_province&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">              <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>Reader和Writer的具体参数可参考<a href="https://github.com/alibaba/DataX/blob/master/README.md">官方文档</a></p><h3 id="3-2DataX命令执行"><a href="#3-2DataX命令执行" class="headerlink" title="3.2DataX命令执行"></a>3.2DataX命令执行</h3><p>DataX的命令执行非常简单，只需要在命令行中执行如下命令：  </p><blockquote><p>python bin&#x2F;datax.py job&#x2F;base_province.json</p></blockquote><h5 id="3-2-1DataX传参"><a href="#3-2-1DataX传参" class="headerlink" title="3.2.1DataX传参"></a>3.2.1DataX传参</h5><p>在生产环境中，离线数据同步任务需要每日定时重复执行，故HDFS上的目标路径通常会包含一层日期，用来对每日同步的数据加以分区，也就是说每日同步数据的目标路径不是固定的，因此DataX配置文件中的DHFSWriter插件中参数path的值应该是动态变化的。为实现这个业务需求，我们需要使用DataX的传参功能<br><strong>DataX传参用法</strong><br>① 首选在任务的json配置文件中使用${param}引用参数<br>② 然后在提交任务时使用-p “-Dparam&#x3D;value” 传入参数值</p><h2 id="4-DataX调优"><a href="#4-DataX调优" class="headerlink" title="4.DataX调优"></a>4.DataX调优</h2><h3 id="4-1DataX运行流程"><a href="#4-1DataX运行流程" class="headerlink" title="4.1DataX运行流程"></a>4.1DataX运行流程</h3><p><img src="https://img01.zzh36111.us.kg/20250124214146.png"></p><h3 id="4-2DataX调度决策思路"><a href="#4-2DataX调度决策思路" class="headerlink" title="4.2DataX调度决策思路"></a>4.2DataX调度决策思路</h3><p>举例来说，用户提交了一个DataX作业，并且配置了总的并发度为20，目的是对一个有100张分表的mysql数据源进行同步。DataX的调度决策思路是：</p><ol><li>DataX Job根据分库分表切分策略(默认一个表一个Task，可以根据业务需要在reader插件中进行切分策略调整)，将同步工作分成100个Task。</li><li>DataX根据配置的总的并发度20，以及每个Task Group的并发度5，DataX计算共需要分配4个TaskGroup。</li><li>4个TaskGroup平分100个Task，每一个TaskGroup负责运行25个Task。</li></ol><h3 id="4-3DataX调优建议"><a href="#4-3DataX调优建议" class="headerlink" title="4.3DataX调优建议"></a>4.3DataX调优建议</h3><ol><li>速度控制:DataX中提供了包括通道（并发）、记录流、字节流三种流控模式，可以根据需要控制你的作业速度，让你的作业在数据库可以承受的范围内达到最佳的同步速度。</li><li>优化参数</li></ol><table><thead><tr><th>参数</th><th>说明</th><th>注意事项</th></tr></thead><tbody><tr><td><code>job.setting.speed.channel</code></td><td>并发数</td><td></td></tr><tr><td><code>job.setting.speed.record</code></td><td>总 record 限速</td><td>配置此参数，则必须配置单个 channel 的 record 限速参数</td></tr><tr><td><code>job.setting.speed.byte</code></td><td>总 byte 限速</td><td>配置此参数，则必须配置单个 channel 的 byte 限速参数</td></tr><tr><td><code>core.transport.channel.speed.record</code></td><td>单个 channel 的 record 限速，默认 10000 条&#x2F;s</td><td></td></tr><tr><td><code>core.transport.channel.speed.byte</code></td><td>单个 channel 的 byte 限速，默认 1M&#x2F;s</td><td></td></tr></tbody></table><p>注意：如果配置了总record限速和总byte限速，channel并发数就会失效。因为配置了这两个参数后，实际的channel并发数是通过计算得到的<br>①计算公式：<br>并发数&#x3D;min(byte_总⁄〖byte〗_单个channel ，  record_总⁄〖record〗_单个channel )<br>② 配置实例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;core&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;transport&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;byte&quot;</span><span class="punctuation">:</span> <span class="number">1048576</span> <span class="comment">//单个channel byte限速1M/s</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;byte&quot;</span> <span class="punctuation">:</span> <span class="number">5242880</span> <span class="comment">//总byte限速5M/s</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        ...</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><!-- <div class="video-container">[up主专用，视频内嵌代码贴在这]</div> --><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: Datax<p>date: 1737698997000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>如何使用Maxwell进行全量表或增量表的数据同步</title>
      <link href="/wenzhang/Maxwell/"/>
      <url>/wenzhang/Maxwell/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Maxwell概述"><a href="#1-Maxwell概述" class="headerlink" title="1.Maxwell概述:"></a>1.Maxwell概述:</h2><p>Maxwell是使用Java编写(可以使用jps查看进程)的MySQL变更数据抓取软件。他会实时监控Mysql数据库的数据变更操作（包括insert、update、delete），并将变更数据以JSON的格式发送给Kafka、Kinesi等流数据处理平台。</p><h2 id="Maxwell输出数据格式"><a href="#Maxwell输出数据格式" class="headerlink" title="Maxwell输出数据格式"></a>Maxwell输出数据格式</h2><table><thead><tr><th>操作</th><th>SQL语句</th><th>数据格式</th></tr></thead><tbody><tr><td>插入</td><td><code>insert into gmall.student values(1, &#39;zhangsan&#39;);</code></td><td>&#96;&#96;&#96;json</td></tr><tr><td></td><td></td><td>{</td></tr><tr><td></td><td></td><td>“database”: “gmall”,</td></tr><tr><td></td><td></td><td>“table”: “student”,</td></tr><tr><td></td><td></td><td>“type”: “insert”,</td></tr><tr><td></td><td></td><td>“ts”: 1634004537,</td></tr><tr><td></td><td></td><td>“xid”: 1530907,</td></tr><tr><td></td><td></td><td>“commit”: true,</td></tr><tr><td></td><td></td><td>“data”: {</td></tr><tr><td></td><td></td><td>“id”: 1,</td></tr><tr><td></td><td></td><td>“name”: “zhangsan”</td></tr><tr><td></td><td></td><td>}</td></tr><tr><td></td><td></td><td>}</td></tr><tr><td></td><td></td><td>&#96;&#96;&#96;</td></tr><tr><td>更新</td><td><code>update gmall.student set name = &#39;lisi&#39; where id=1;</code></td><td>&#96;&#96;&#96;json</td></tr><tr><td></td><td></td><td>{</td></tr><tr><td></td><td></td><td>“database”: “gmall”,</td></tr><tr><td></td><td></td><td>“table”: “student”,</td></tr><tr><td></td><td></td><td>“type”: “update”,</td></tr><tr><td></td><td></td><td>“ts”: 1634004657,</td></tr><tr><td></td><td></td><td>“xid”: 1531916,</td></tr><tr><td></td><td></td><td>“commit”: true,</td></tr><tr><td></td><td></td><td>“data”: {</td></tr><tr><td></td><td></td><td>“id”: 1,</td></tr><tr><td></td><td></td><td>“name”: “lisi”</td></tr><tr><td></td><td></td><td>},</td></tr><tr><td></td><td></td><td>“old”: {</td></tr><tr><td></td><td></td><td>“name”: “zhangsan”</td></tr><tr><td></td><td></td><td>}</td></tr><tr><td></td><td></td><td>}</td></tr><tr><td></td><td></td><td>&#96;&#96;&#96;</td></tr><tr><td>删除</td><td><code>delete from gmall.student where id=1;</code></td><td>&#96;&#96;&#96;json</td></tr><tr><td></td><td></td><td>{</td></tr><tr><td></td><td></td><td>“database”: “gmall”,</td></tr><tr><td></td><td></td><td>“table”: “student”,</td></tr><tr><td></td><td></td><td>“type”: “delete”,</td></tr><tr><td></td><td></td><td>“ts”: 1634004751,</td></tr><tr><td></td><td></td><td>“xid”: 1532725,</td></tr><tr><td></td><td></td><td>“commit”: true,</td></tr><tr><td></td><td></td><td>“data”: {</td></tr><tr><td></td><td></td><td>“id”: 1,</td></tr><tr><td></td><td></td><td>“name”: “lisi”</td></tr><tr><td></td><td></td><td>}</td></tr><tr><td></td><td></td><td>}</td></tr><tr><td></td><td></td><td>&#96;&#96;&#96;</td></tr></tbody></table><p><strong>字段说明：</strong></p><ol><li><code>database</code>：变更数据所属的数据库</li><li><code>commit</code>：事务提交标志，可用于重新组装事务。 </li><li>xid：事务ID，用于标识事务。 </li><li>ts：变更数据的时间戳。 </li><li>type：变更数据的类型，包括insert、update、delete。 </li><li>data：变更数据，包括新增或修改的数据。 </li><li>old：变更前的数据，仅在update操作时存在。</li></ol><h2 id="2-Maxwell的实现原理"><a href="#2-Maxwell的实现原理" class="headerlink" title="2.Maxwell的实现原理"></a>2.Maxwell的实现原理</h2><p>Maxwell的实现原理很简单，就是将自己伪装成Slave，并遵循Mysql主从复制的协议，从master中同步数据。<br><strong>Mysql主从复制工作原理</strong><img src="https://img01.zzh36111.us.kg/20250123182703.png"><br>① Master主库接收到数据变更请求，完成数据变更，并将其写到二级制日志（binary log）中。<br>② Slave从库向Mysql master发送dump协议，将Master主库的binary log events拷贝到从库的中继日志（relay log）中。<br>③ Slave从库读取并回放中继日志中的事件，将更新的数据同步到自己的数据库中。</p><h2 id="3-Maxwell部署"><a href="#3-Maxwell部署" class="headerlink" title="3.Maxwell部署"></a>3.Maxwell部署</h2><h3 id="1-配置MySQL"><a href="#1-配置MySQL" class="headerlink" title="1.配置MySQL"></a>1.配置MySQL</h3><h4 id="1-1"><a href="#1-1" class="headerlink" title="1.1"></a>1.1</h4><p>配置MySQL启动MySQL Binlog（修改MySQL的配置文件&#x2F;etc&#x2F;my.cnf重启Mysql服务后才生效）</p><h4 id="2-1"><a href="#2-1" class="headerlink" title="2.1"></a>2.1</h4><p>Mysql Binlog模式介绍<br>① Statement-based: 基于语句，Binlog会记录所有写操作的SQL语句，包括：insert、update、delete等。<br>                    优点：节省空间；<br>                    缺点：有可能造成数据不一致，如：insert语句中包含now()函数。<br>② Row-based：       基于行，Binlog会记录每次写操作的被操作行记录的变化。<br>                    优点：保持数据的绝对一致性<br>                    缺点：占用较大空间<br>③ mixed：   混合模式，默认是Statement-based，如果SQL语句可能导致数据不一致，就自动切换到Row-based<br>Maxwell要求Binlog采用Row-based模式</p><h3 id="2-创建Maxwell所需数据库和用户"><a href="#2-创建Maxwell所需数据库和用户" class="headerlink" title="2.创建Maxwell所需数据库和用户"></a>2.创建Maxwell所需数据库和用户</h3><h3 id="3-配置Maxwell"><a href="#3-配置Maxwell" class="headerlink" title="3.配置Maxwell"></a>3.配置Maxwell</h3><h4 id="3-1"><a href="#3-1" class="headerlink" title="3.1"></a>3.1</h4><p>修改Maxwell的配置文件config.properties,主要是配置数据发送的目的地。（若Maxwell发送数据的目的地是kafka集群，需要首先将kafka集群启动。）</p><h2 id="4-启动Maxwell"><a href="#4-启动Maxwell" class="headerlink" title="4.启动Maxwell"></a>4.启动Maxwell</h2><p>Maxwell的启动命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/maxwell --config config.properties --daemon</span><br></pre></td></tr></table></figure><p>Maxwell关闭命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep maxwell | grep -v grep | grep maxwell | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9</span><br></pre></td></tr></table></figure><h3 id="Maxwell全量数据同步流程命令"><a href="#Maxwell全量数据同步流程命令" class="headerlink" title="Maxwell全量数据同步流程命令"></a>Maxwell全量数据同步流程命令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/maxwell-bootstrap --database edu --table user_info --config config.properties</span><br></pre></td></tr></table></figure><!-- <div class="video-container">[up主专用，视频内嵌代码贴在这]</div> --><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: 如何使用Maxwell进行全量表或增量表的数据同步<p>date: 1737624278000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>在线教育离线数仓之数据采集</title>
      <link href="/wenzhang/%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
      <url>/wenzhang/%E5%9C%A8%E7%BA%BF%E6%95%99%E8%82%B2%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<!-- <div class="video-container">[up主专用，视频内嵌代码贴在这]</div> --><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style><!-- ---title: 在线教育离线数仓之数据采集<p>date: 1737542912000<br>tags:<br>— –&gt;</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/wenzhang/hello-world/"/>
      <url>/wenzhang/hello-world/</url>
      
        <content type="html"><![CDATA[<h1 id="博客预览"><a href="#博客预览" class="headerlink" title="博客预览"></a>博客预览</h1><blockquote><p>hexo cl; hexo s</p></blockquote><h1 id="推送"><a href="#推送" class="headerlink" title="推送"></a>推送</h1><blockquote><p>hexo cl; hexo g; hexo d</p></blockquote><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><h2 id="基本语法-1"><a href="#基本语法-1" class="headerlink" title="基本语法"></a>基本语法</h2><h3 id="基本语法-2"><a href="#基本语法-2" class="headerlink" title="基本语法"></a>基本语法</h3><p><strong>引用</strong></p><ol><li>hjjk </li><li>jkdsfjl</li></ol><ul><li>skolfakashjd </li><li>kdsfjfjljds<br>djlksgjdfjksldfjl</li></ul><ul><li>sakllflj</li></ul><ul><li>sakhaklfhk</li></ul><ol><li>lsalk</li></ol><table><thead><tr><th>表头 1</th><th>表头 2</th></tr></thead><tbody><tr><td>内容 1</td><td>内容 2</td></tr><tr><td>内容 3</td><td>内容 4</td></tr></tbody></table><div style="text-align: center;"><table><thead><tr><th align="right">kalfl</th><th align="center">ldskkfldg</th></tr></thead><tbody><tr><td align="right">lslfjkk</td><td align="center">kdjfglk</td></tr></tbody></table></div><div style="text-align: center;"><table><thead><tr><th>服务名称</th><th>子服务</th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td>HDFS</td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td>HDFS</td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Yarn</td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume(采集日志)</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka日志）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Flume（消费Kafka业务）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td>Hive</td><td>√</td><td></td><td></td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>DataX</td><td>DataX</td><td>√</td><td></td><td></td></tr><tr><td>Maxwell</td><td>Maxwell</td><td>√</td><td></td><td></td></tr><tr><td>Spark</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>ClickHouse</td><td></td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>ApiApplicationServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>AlertServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>MasterServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>WorkerServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>LoggerServer</td><td>√</td><td>√</td><td>√</td></tr></tbody></table></div>`dfhjkgh`<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lhjsdfkhs</span><br><span class="line">jkhdsfkj</span><br></pre></td></tr></table></figure><p>alt+shift+f格式化表格</p><p><a href="https://cmliussss.com/p/HexoBlogNo2/">超链接</a>：<a href="https://cmliussss.com/p/HexoBlogNo2/">https://cmliussss.com/p/HexoBlogNo2/</a></p><p>请<a href="https://cmliussss.com/p/HexoBlogNo2/">点我</a></p><h1 id="服务部署情况"><a href="#服务部署情况" class="headerlink" title="服务部署情况"></a>服务部署情况</h1><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>在线教育离线数仓使用的脚本合集</title>
      <link href="/wenzhang/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE/"/>
      <url>/wenzhang/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="1-集群执行命令脚本："><a href="#1-集群执行命令脚本：" class="headerlink" title="1. 集群执行命令脚本："></a>1. 集群执行命令脚本：</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"> </span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo --------- $i ----------</span><br><span class="line">    ssh $i &quot;$*&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="2-集群同步脚本"><a href="#2-集群同步脚本" class="headerlink" title="2. 集群同步脚本"></a>2. 集群同步脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录(dirname获取绝对路径父目录,相对路径获取的是.）</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir #-av是打印进度的</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="3-Hadoop启动脚本"><a href="#3-Hadoop启动脚本" class="headerlink" title="3. Hadoop启动脚本"></a>3. Hadoop启动脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;No Args Input...&quot;</span><br><span class="line">    exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">        echo &quot; =================== 启动 hadoop集群 ===================&quot;</span><br><span class="line"></span><br><span class="line">        echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/sbin/start-dfs.sh&quot;</span><br><span class="line">        echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line">        ssh hadoop103 &quot;/opt/module/hadoop/sbin/start-yarn.sh&quot;</span><br><span class="line">        echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/bin/mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">        echo &quot; =================== 关闭 hadoop集群 ===================&quot;</span><br><span class="line"></span><br><span class="line">        echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/bin/mapred --daemon stop historyserver&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line">        ssh hadoop103 &quot;/opt/module/hadoop/sbin/stop-yarn.sh&quot;</span><br><span class="line">        echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="4-Zookeeper启动脚本"><a href="#4-Zookeeper启动脚本" class="headerlink" title="4. Zookeeper启动脚本"></a>4. Zookeeper启动脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">判断是否输入参数</span></span><br><span class="line">if [ $# -lt 1 ]; then</span><br><span class="line">  echo &quot;请输入参数&quot;</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo ---------- zookeeper $i 启动 ------------</span><br><span class="line">                ssh $i &quot;/opt/module/zookeeper/bin/zkServer.sh start&quot;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo ---------- zookeeper $i 停止 ------------    </span><br><span class="line">                ssh $i &quot;/opt/module/zookeeper/bin/zkServer.sh stop&quot;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;status&quot;)&#123;</span><br><span class="line">        for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">        do</span><br><span class="line">        echo ---------- zookeeper $i 状态 ------------    </span><br><span class="line">                ssh $i &quot;/opt/module/zookeeper/bin/zkServer.sh status&quot;</span><br><span class="line">        done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="5-Kafka启动脚本"><a href="#5-Kafka启动脚本" class="headerlink" title="5. Kafka启动脚本"></a>5. Kafka启动脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">判断是否输入参数</span></span><br><span class="line">if [ $# -lt 1 ]; then</span><br><span class="line">  echo &quot;请输入参数&quot;</span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo &quot; --------启动 $i Kafka-------&quot;</span><br><span class="line">        ssh $i &quot;/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties&quot;</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo &quot; --------停止 $i Kafka-------&quot;</span><br><span class="line">        ssh $i &quot;/opt/module/kafka/bin/kafka-server-stop.sh &quot;</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><p>maxwell启动脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">MAXWELL_HOME=/opt/module/maxwell</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">grep -v grep是为了过滤掉grep本身的进程</span></span><br><span class="line">result=$(ps -ef | grep Maxwell | grep -v grep)</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">start )</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">判断result是否为空</span></span><br><span class="line">    if [ -z &quot;$result&quot; ]; then</span><br><span class="line">        echo &quot;启动Maxwell&quot;</span><br><span class="line">        $MAXWELL_HOME/bin/maxwell --config $MAXWELL_HOME/config.properties --daemon</span><br><span class="line">    else</span><br><span class="line">         echo &quot;Maxwell正在运行&quot;</span><br><span class="line">    fi</span><br><span class="line">;;</span><br><span class="line">stop )</span><br><span class="line">    if [ -z &quot;$result&quot; ]; then</span><br><span class="line">        echo &quot;Maxwell未在运行&quot;</span><br><span class="line">    else</span><br><span class="line">echo &quot;停止Maxwell&quot;</span><br><span class="line">        ps -ef | grep Maxwell | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9</span><br><span class="line">    fi</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><!-- <div class="video-container">[up主专用，视频内嵌代码贴在这]</div> --><style>.video-container {    position: relative;    width: 100%;    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */}.video-container iframe {    position: absolute;    top: 0;    left: 0;    width: 100%;    height: 100%;}</style>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>大数据项目之在线教育离线数仓</title>
      <link href="/wenzhang/%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E6%96%B0%E7%9A%84%E5%8D%9A%E6%96%87/"/>
      <url>/wenzhang/%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E6%96%B0%E7%9A%84%E5%8D%9A%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="大数据开发项目之在线教育离线数仓从零到一（学习项目）"><a href="#大数据开发项目之在线教育离线数仓从零到一（学习项目）" class="headerlink" title="大数据开发项目之在线教育离线数仓从零到一（学习项目）"></a>大数据开发项目之在线教育离线数仓从零到一（学习项目）</h1><p>本文详细介绍了大数据开发项目之在线教育离线数仓的开发过程，从零到一，包括项目背景、需求分析、设计思路、技术选型、开发环境搭建、数据采集、数仓搭建、</p><h2 id="项目整体流程"><a href="#项目整体流程" class="headerlink" title="项目整体流程"></a>项目整体流程</h2><p>该项目是一个在线教育大数据开发项目，旨在构建离线数仓，对在线教育业务数据进行分析处理，以支持企业决策。以下是项目的详细流程：</p><h3 id="1-业务流程与数据来源"><a href="#1-业务流程与数据来源" class="headerlink" title="1. 业务流程与数据来源"></a>1. 业务流程与数据来源</h3><ul><li><strong>业务流程</strong>：用户从在线教育网站首页开始浏览课程，可通过分类查询或全文检索寻找课程，找到后可添加到购物车、登录、结算，生成订单和支付数据，订单生成后会进行跟踪处理。</li><li><strong>数据来源</strong>：包括用户行为数据（通过前端埋点采集，存储在 HDFS 文件中）和业务数据（存储在 MySQL 中）。(因为本项目为学习项目，所以数据来源均为数据模拟器模拟的虚拟数据)</li></ul><h3 id="2-系统数据流程设计"><a href="#2-系统数据流程设计" class="headerlink" title="2. 系统数据流程设计"></a>2. 系统数据流程设计</h3><ul><li><strong>集群流程图</strong>：业务服务器与 App 业务交互，通过 Nginx 进行数据传输。日志数据经日志服务器采集，可采用 flume 采集方式，部分数据经消息缓存后存入 Kafka。业务数据通过 DataX 每日同步从 MySQL 数据库导入。数据在集群中经过 ODS、DWD、DWS 等层的处理，最终用于可视化。<br><img src="https://img01.zzh36111.us.kg/20250122151413.png" alt="流程图"><br>问：为什么不直接使用flume把数据采集到hdfs，要在之间加一个kafka呢？可以把Kafka换为flume聚合吗？</li><li><strong>集群特点</strong>：具备多数据源对接能力，可进行离线批量和在线实时处理，有统一的集群管理配置监控平台，并实现用户认证和权限管理，满足多租户需求。</li></ul><h3 id="3-技术选型"><a href="#3-技术选型" class="headerlink" title="3. 技术选型"></a>3. 技术选型</h3><ul><li><p><strong>Apache 框架版本</strong>：确定了 Hadoop、Flume、Kafka、Hive、Sqoop 等多种技术框架的具体版本，每个版本都有其特定的功能特点，以满足项目需求。</p><table><thead><tr><th>框架</th><th>版本</th></tr></thead><tbody><tr><td>Hadoop</td><td>3.1.3</td></tr><tr><td>Zookeeper</td><td>3.5.7</td></tr><tr><td>MySQL</td><td>5.7.16</td></tr><tr><td>Hive</td><td>3.1.2</td></tr><tr><td>Flume</td><td>1.9.0</td></tr><tr><td>Kafka</td><td>3.0.0</td></tr><tr><td>Spark</td><td>3.0.0</td></tr><tr><td>DataX</td><td>3.0.0</td></tr><tr><td>Superset</td><td>1.3.2</td></tr><tr><td>DolphinScheduler</td><td>2.0.3</td></tr><tr><td>Maxwell</td><td>1.29.2</td></tr></tbody></table></li><li><p><strong>服务器选型</strong>：因为本项目仅为学习项目所以服务器选型比较简单仅为三台虚拟机。</p></li></ul><h3 id="4-集群规模规划"><a href="#4-集群规模规划" class="headerlink" title="4. 集群规模规划"></a>4. 集群规模规划</h3><ul><li><p><strong>集群规划</strong>：详细规划了各服务器节点上部署的组件，如 DataNode、NodeManager、ResourceManager 等在不同服务器上的分布。</p><table><thead><tr><th>服务名称</th><th>子服务</th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td>HDFS</td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td>HDFS</td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Yarn</td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume(采集日志)</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka日志）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Flume（消费Kafka业务）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td>Hive</td><td>√</td><td></td><td></td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>DataX</td><td>DataX</td><td>√</td><td></td><td></td></tr><tr><td>Maxwell</td><td>Maxwell</td><td>√</td><td></td><td></td></tr><tr><td>Spark</td><td></td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>ApiApplicationServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>AlertServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>MasterServer</td><td>√</td><td></td><td></td></tr><tr><td>DolphinScheduler</td><td>WorkerServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>DolphinScheduler</td><td>LoggerServer</td><td>√</td><td>√</td><td>√</td></tr></tbody></table></li></ul><h3 id="5-数据仓库学习重点"><a href="#5-数据仓库学习重点" class="headerlink" title="5. 数据仓库学习重点"></a>5. 数据仓库学习重点</h3><ol><li>建模（建表）</li><li>SQL及优化</li><li>任务调度器</li></ol><p>如果直接将MySQL作为数据仓库数据源</p><ol><li>MySQL为行存储，数仓为列存储</li><li>MySQL不是海量数据，数据仓库要求海量数据（因为数据量越大，分析结果越准确）</li><li>会降低MySQL的查询性能</li><li>所以数仓设计自己的数据源要求汇总数据</li><li>加hdfs(因为数仓采用hive)为解耦合，数据源和数仓分离，数据源只负责采集数据，数仓只负责分析数据</li><li></li></ol><!-- ### 5. 数据生成与分析指标 - **数据生成器使用**：通过上传相关配置文件（application.yml、path.json、logback.xml 等）到指定目录，并修改配置文件参数，可在虚拟机指定路径下生成日志数据并向业务数据库插入业务数据。可生成不同日期数据，且能灵活配置用户点击路径和日志生成路径。 - **分析指标**：涵盖流量主题（如各来源流量统计、路径分析、各来源下单统计）、用户主题（如用户变动统计、留存率、新增活跃统计等）、课程主题（如各分类课程交易统计、评价统计、试听留存统计等）、交易主题、考试主题、播放主题、完课主题等多方面的指标，每个指标都有明确的统计周期和粒度要求。 -->]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
